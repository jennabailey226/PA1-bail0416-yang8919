// This autogenerated skeleton file illustrates how to build a server.
// You should copy it to another filename to avoid overwriting it.

#include "./gen-cpp/Coordinator.h"
#include "./gen-cpp/ComputeNode.h"
#include <thrift/protocol/TBinaryProtocol.h>
#include <thrift/server/TSimpleServer.h>
#include <thrift/transport/TServerSocket.h>
#include <thrift/transport/TBufferTransports.h>
#include <thrift/transport/TSocket.h>
#include <thrift/transport/TTransportUtils.h>
#include <thread>
#include <queue>
#include <sstream>
#include "./ML/ML/ML.hpp"

using namespace ::apache::thrift;
using namespace ::apache::thrift::protocol;
using namespace ::apache::thrift::transport;
using namespace ::apache::thrift::server;

using namespace  ::distributedML;

class CoordinatorHandler : virtual public CoordinatorIf {
 public:
  CoordinatorHandler() {
    // Your initialization goes here
  }

  void load_compute_nodes(std::vector<ComputeNodeInfo> & _return, const std::string& filename) {
    //std::ifstream file("/home/yang8919/PA1-bail0416-yang8919-yahui/" + filename);
    std::ifstream file("./" + filename);
    if (!file.is_open()) {
      std::cout << "Error: Unable to open file " << filename << std::endl;
      exit(1);
    }
    std::string line;
    while (getline(file, line)) {
      ComputeNodeInfo in;
      std::stringstream ss(line);
      char delimiter;
      if (!(ss >> in.ip >> delimiter >> in.port >> in.load_probability) || delimiter != ',') {
        std::cout << "Error: Invalid format in file: " << line << std::endl;
        exit(1);
      }
      _return.emplace_back(in);
    }
    file.close();
  }

  double train(const std::string& dir, const int32_t rounds, const int32_t epochs, const int32_t h, const int32_t k, const double eta, const std::string& compute_nodes_file) {
    std::cout << "Coordinator: rounds: " << rounds << " epocks: " << epochs << " hidden unit: "
      << h << " output unit: " << k << " learning rate: " << eta << std::endl;

    // Initialize the global model
    mlp almighty;
    // only read the input data's format, weights are random
    almighty.init_training_random(dir + "/train_letters1.txt", k, h);

    Weights shared_weights;
    almighty.get_weights(shared_weights.V, shared_weights.W);

    queue<std::string> work_queue;
    for (int i = 1; i < 2; i++) {
        work_queue.push(dir + "/train_letters" + std::__cxx11::to_string(i) + ".txt");
    }

    std::vector<ComputeNodeInfo> compute_nodes;
    load_compute_nodes(compute_nodes, compute_nodes_file);
    if (compute_nodes.empty()) {
      std::cout << "Error: No compute nodes found in " << compute_nodes_file << std::endl;
      exit(1);
    }

    std::vector<vector<double>> shared_gradient_V(h + 1, vector<double>(k, 0));
    std::vector<vector<double>> shared_gradient_W(17, vector<double>(h, 0));
    auto thread_func = [&](int node_index) {
      while (true){
        if (work_queue.empty()) {
          return;
        }
        std::string training_file = work_queue.front();
        work_queue.pop();
        std::shared_ptr<TTransport> socket(new TSocket(compute_nodes[node_index].ip, compute_nodes[node_index].port));
        std::shared_ptr<TTransport> transport(new TBufferedTransport(socket));
        std::shared_ptr<TProtocol> protocol(new TBinaryProtocol(transport));
        ComputeNodeClient client(protocol);

        transport->open();
        Gradient grad;
        client.trainModel(grad, shared_weights, training_file, eta, epochs);
        transport->close();

        for (int i = 0; i < shared_gradient_V.size(); i++) {
          for (int j = 0; j < shared_gradient_V[i].size(); j++) {
              shared_gradient_V[i][j] += grad.dV[i][j];
          }
        }
        for (int i = 0; i < shared_gradient_W.size(); i++) {
          for (int j = 0; j < shared_gradient_W[i].size(); j++) {
              shared_gradient_W[i][j] += grad.dW[i][j];
          }
        }
      }
    };
    std::vector<std::thread> workers;
    for (int i = 0; i < compute_nodes.size(); i++) {
        workers.emplace_back(thread_func, i);
    }
    for (auto& worker : workers) {
        worker.join();
    }
    almighty.update_weights(shared_gradient_V, shared_gradient_W);
    double validation_error = almighty.validate(dir + "/validate_letters.txt");
    //cout << "Validation error: " << validation_error << endl;
    return validation_error;
  }

};

int main(int argc, char **argv) {
  if (argc != 3) {
      std::cout << "Usage: ./coordinator <port> <scheduling_policy>" << std::endl;
      exit(1);
  }
  int port = std::__cxx11::stoi(argv[1]);
  std::string policy = argv[2];
  ::std::shared_ptr<CoordinatorHandler> handler(new CoordinatorHandler());
  ::std::shared_ptr<TProcessor> processor(new CoordinatorProcessor(handler));
  ::std::shared_ptr<TServerTransport> serverTransport(new TServerSocket(port));
  ::std::shared_ptr<TTransportFactory> transportFactory(new TBufferedTransportFactory());
  ::std::shared_ptr<TProtocolFactory> protocolFactory(new TBinaryProtocolFactory());

  TSimpleServer server(processor, serverTransport, transportFactory, protocolFactory);
  server.serve();
  return 0;
}
